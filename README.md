# Решение тестового задания

## Введение

В данном проекте представлен процесс решения тестового задания, включавшего в себя 3 задачи:

- 1. Отобразить список городов, в которых температура поднималась выше значения средней температуры за все время наблюдений. Сортировка городов по алфавиту;
- 2. Отобразить диаграмму средней температуры по каждому месяцу за первый календарный год наблюдений;
- 3. Вывести список 3х лучших городов для жизни, по мнению одной из популярных LLM, с кратким описанием (на русском языке) причин такого выбора возле каждого из городов.


Для последнего я использовал такие модели, как `sentence-transformers/all-MiniLM-L6-v2`, `microsoft/phi-2`, а также сервис Pinecone для поиска ближайших соседей.Основная цель заключалась в определении городов с умеренной температурой, низким количеством жарких и холодных периодов, а также низкой скоростью ветра.

## Используемые модели

### `sentence-transformers/all-MiniLM-L6-v2`

**Преимущества:**
- Высокая производительность при создании векторных представлений текста.
- Хорошо подходит для задач поиска и сравнения текстов.
- Компактная модель, которая быстро обрабатывает запросы.

**Недостатки:**
- Ограниченная контекстная информация по сравнению с более крупными моделями.
- Может не учитывать всю семантическую глубину сложных текстов.

### `microsoft/phi-2`

**Преимущества:**
- Высокая точность генерации текста.
- Способна генерировать текст на основе сложных запросов и контекста.

**Недостатки:**
- Большой размер модели требует значительных вычислительных ресурсов.
- Модель может иногда генерировать тексты с некорректной информацией.

### `google/tapas-large-finetuned-wtq`

**Преимущества:**
- Способна отвечать на вопросы, основываясь на табличных данных.
- Высокая точность ответов на вопросы, связанные с табличной информацией.

**Недостатки:**
- Требует значительных вычислительных ресурсов.
- Ограниченная длина входных данных может потребовать разделения больших таблиц на части.

## Используемые подходы

### Векторизация данных и поиск ближайших соседей

Я использовал модель `sentence-transformers/all-MiniLM-L6-v2` для создания векторных представлений описаний городов. С помощью Pinecone я выполнял поиск ближайших соседей для определения схожести текстов.

### Генерация текста на основе описаний

Для генерации описаний и ответа на запросы я использовал модель `microsoft/phi-2`. Сгенерированные тексты затем переводились на русский язык с использованием библиотеки `googletrans`.

### Ответы на вопросы на основе табличных данных

Для получения ответов на вопросы, связанные с табличными данными, я использовал модель `google/tapas-large-finetuned-wtq`.

## Процесс работы

### Подготовка данных
- Загрузка и предварительная обработка данных о погоде из CSV-файла.

### Задание 1
- Решение задания 1 заняло около 10 минут.

### Задание 2
- Решение задания 2 заняло около 3 минут.

### Задание 3
- Решение задания 3 заняло 5 часов, из которых 2 часа анализ моделей и возможности их применения, 3 часа тестирование и разработка алгоритмов.

### Подготовка данных
- Загрузка и предварительная обработка данных о погоде из CSV-файла.
- Группировка данных по городам и расчет средних значений температуры и скорости ветра.
- Классификация температур и скорости ветра по категориям (холодная, комфортная, жаркая; слабый, умеренный, сильный, ураганный ветер).
- Создание описаний для каждого города на основе рассчитанных значений.

### Векторизация и загрузка данных в Pinecone
- Преобразование описаний городов в векторные представления с помощью `sentence-transformers/all-MiniLM-L6-v2`.
- Загрузка векторных представлений в индекс Pinecone для последующего поиска.

### Генерация текстов и поиск лучших городов
- Формирование запросов на основе описаний городов и генерация текстов с использованием модели `microsoft/phi-2`.
- Поиск ближайших соседей в Pinecone для определения наиболее подходящих городов.
- Перевод сгенерированных текстов на русский язык с использованием библиотеки `googletrans`.

### Подготовка кода и оформление на GitHub (30 минут)
- Подготовка кода для загрузки на GitHub.
- Оформление репозитория и загрузка кода.

## Краткие выводы

Модель `google/tapas-large-finetuned-wtq` хорошо подходит для работы с табличными данными, но не позволяет генерировать развернутые ответы. Использование векторной разметки с Pinecone не улучшило результаты и до сих пор присутствуют галлюцинации. Модель `microsoft/phi-2` показала неплохие результаты, при условии, что я отбираю признаки для анализа. Реализация также возможна через API OpenAI с использованием Langchain, однако я не стал использовать этот подход, так как он не является обучением LLM, а лишь адресует вопрос модели.
